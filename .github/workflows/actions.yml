name: Deploy Infrastructure

on:
  workflow_dispatch:
    inputs:
      ENVIRONMENT: # variable
        description: 'Deploy Environment (dev/prod)'
        required: true
        default: '[dev],prod' # install chrome extension for drop down menu (see readme)
      DEPLOY_CLUSTERS: # variable
        description: 'Create Clusters (true/false/destroy)'
        required: true
        default: '[true],false,destroy' # install chrome extension for drop down menu (see readme)
      DEPLOY_UC_STORAGE_CRED: # variable
        description: 'Create UC Storage Credential (true/false/destroy)'
        required: true
        default: '[true],false,destroy' # install chrome extension for drop down menu (see readme)
      DEPLOY_UC_SCHEMA: # variable
        description: 'Create UC Schema (true/false/destroy)'
        required: true
        default: '[true],false,destroy' # install chrome extension for drop down menu (see readme)

  push:
    branches:
      - main

jobs:
  deploy:
    name: 'Terraform Plan and Apply'
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./terraform

    env:
      TF_VAR_environment: ${{ github.event.inputs.ENVIRONMENT || secrets.ENVIRONMENT  }}
      TF_VAR_aws_region: ${{ secrets.AWS_REGION }}
      TF_VAR_aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
      TF_VAR_aws_access_key_secret: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      TF_VAR_databricks_account_id: ${{ secrets.DATABRICKS_ACCOUNT_ID }}
      TF_VAR_databricks_instances: '{"dev": "${{ secrets.DATABRICKS_INSTANCE_DEV }}", "prod": "${{ secrets.DATABRICKS_INSTANCE_PROD }}"}'
      TF_VAR_databricks_client_ids: '{"dev": "${{ secrets.DATABRICKS_CLIENT_ID_DEV }}", "prod": "${{ secrets.DATABRICKS_CLIENT_ID_PROD }}"}'
      TF_VAR_databricks_client_secrets: '{"dev": "${{ secrets.DATABRICKS_CLIENT_SECRET_DEV }}", "prod": "${{ secrets.DATABRICKS_CLIENT_ID_SECRET_PROD }}"}'
      # TF_VAR_databricks_tokens: '{"dev": "${{ secrets.DATABRICKS_TOKEN_DEV }}", "prod": "${{ secrets.DATABRICKS_TOKEN_PROD }}"}'
      TF_VAR_databricks_admin_login: ${{ secrets.DATABRICKS_ADMIN_LOGIN }}
      TF_VAR_databricks_admin_password: ${{ secrets.DATABRICKS_ADMIN_PASSWORD }}
      TF_VAR_github_actor: ${{ github.actor }} # username for tagging of resources
      # default to no if running directly from push to main branch so we execute a simple workflow run unit test
      # if running workflow manually then you can deploy clusters
      TF_VAR_databricks_deploy_clusters: ${{ github.event.inputs.DEPLOY_CLUSTERS || 'false' }}
      # if running workflow manually then you can deploy uc storage credentials
      TF_VAR_databricks_deploy_uc_storage_credential: ${{ github.event.inputs.DEPLOY_UC_STORAGE_CRED || 'false' }}
      # if running workflow manually then you can deploy uc storage credentials
      TF_VAR_databricks_deploy_uc_schema: ${{ github.event.inputs.DEPLOY_UC_SCHEMA || 'false' }}


    steps:

      - name: Checkout repository
        uses: actions/checkout@v3
  
      - name: Set up latest version of Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.x'

      - name: Install jq
        run: sudo apt-get install jq

      - name: Create Terraform Init Backend Configuration
        run: |
          BACKEND_BUCKET_DEV=$(jq -r .backend_bucket_dev < ../terraform/shell_scripts/tf_s3_backend/tf_s3_backend_config.json)
          BACKEND_BUCKET_PROD=$(jq -r .backend_bucket_prod < ../terraform/shell_scripts/tf_s3_backend/tf_s3_backend_config.json)
          echo "BACKEND_BUCKET_DEV=$BACKEND_BUCKET_DEV" >> $GITHUB_ENV
          echo "BACKEND_BUCKET_PROD=$BACKEND_BUCKET_PROD" >> $GITHUB_ENV

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v1

      - name: Setup Terraform Init Backend
        run: |
          export TF_LOG=DEBUG
          if [[ "${{ env.TF_VAR_environment }}" == "dev" ]]; then
            export BUCKET_NAME="${{ env.BACKEND_BUCKET_DEV }}"
          else
            export BUCKET_NAME="${{ env.BACKEND_BUCKET_PROD }}"
          fi
          export KEY_NAME="terraform/terraform.tfstate"
          export AWS_REGION="${{ env.TF_VAR_aws_region }}"
          export ACCESS_KEY="${{ env.TF_VAR_aws_access_key_id }}"
          export SECRET_KEY="${{ env.TF_VAR_aws_access_key_secret}}"
          chmod +x ../terraform/shell_scripts/tf_s3_backend/tf_s3_backend_deploy.sh
          ../terraform/shell_scripts/tf_s3_backend/tf_s3_backend_deploy.sh

      - name: Create Databricks Auth Token Configuration
        run: |
          export TF_VAR_environment="${{env.TF_VAR_environment}}"
          export DATABRICKS_ACCOUNT_ID="${{ env.TF_VAR_databricks_account_id }}"
          export DATABRICKS_CLIENT_ID=$(echo $TF_VAR_databricks_client_ids | jq -r .${{env.TF_VAR_environment}})
          export DATABRICKS_CLIENT_SECRET=$(echo $TF_VAR_databricks_client_secrets | jq -r .${{env.TF_VAR_environment}})

      - name: Get Databricks Auth Token
        run: |
          pip3 install -r ../terraform/python/requirements.txt
          chmod +x ../terraform/python/get_dbricks_token.py
          TF_VAR_databricks_token=$(python3 ../terraform/python/get_dbricks_token.py)
          echo "TF_VAR_databricks_token=$TF_VAR_databricks_token" >> $GITHUB_ENV

      - name: Terraform Validate
        run: |
          export TF_LOG=DEBUG
          terraform validate

      - name: Terraform Plan
        run: terraform plan
          
      - name: Deploy / Destroy Databricks Clusters
        run: |
          if [[ "${{ env.TF_VAR_databricks_deploy_clusters }}" == "true" ]]; then
            terraform apply --auto-approve -target=module.cluster_module.databricks_cluster.this
          elif [[ "${{ env.TF_VAR_databricks_deploy_clusters }}" == "destroy" ]]; then
            terraform destroy --auto-approve -target=module.cluster_module.databricks_cluster.this
          fi

      - name: Deploy / Destroy Unity Catalog Storage Credential
        run: |
          if [[ "${{ env.TF_VAR_databricks_deploy_uc_storage_credential }}" == "true" ]]; then
            terraform apply --auto-approve -target=module.uc_sc_module.databricks_storage_credential.external
            terraform apply --auto-approve -target=module.uc_sc_module.databricks_grants.external_creds
          elif [[ "${{ env.TF_VAR_databricks_deploy_uc_storage_credential }}" == "destroy" ]]; then
            terraform destroy --auto-approve -target=module.uc_sc_module.databricks_storage_credential.external
            terraform destroy --auto-approve -target=module.uc_sc_module.databricks_grants.external_creds
          fi

      - name: Deploy / Destroy Unity Catalog Schema
        run: |
          if [[ "${{ env.TF_VAR_databricks_deploy_uc_schema }}" == "true" ]]; then
            terraform apply --auto-approve -target=module.uc_schema_module.databricks_schema.schema
            terraform apply --auto-approve -target=module.uc_schema_module.databricks_grants.schema
          elif [[ "${{ env.TF_VAR_databricks_deploy_uc_schema }}" == "destroy" ]]; then
            terraform destroy --auto-approve -target=module.uc_schema_module.databricks_schema.schema
            terraform destroy --auto-approve -target=module.uc_schema_module.databricks_grants.schema
          fi